{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR63sM6_IkYN",
        "outputId": "d7693de4-9dfb-4267-a451-ab331f75cbb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: yfinance in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (0.2.38)\n",
            "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.31 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (3.17.5)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
            "Requirement already satisfied: six>=1.9 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.31->yfinance) (3.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.31->yfinance) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.31->yfinance) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.31->yfinance) (2022.12.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: optuna in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (3.6.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (2.0.4)\n",
            "Requirement already satisfied: tqdm in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: Mako in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from alembic>=1.5.0->optuna) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=4 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from colorlog->optuna) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pandas_ta\n",
            "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
            "     ---------------------------------------- 0.0/115.1 kB ? eta -:--:--\n",
            "     -------------------------------------- 115.1/115.1 kB 7.0 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: pandas in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from pandas_ta) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from pandas->pandas_ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from pandas->pandas_ta) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from pandas->pandas_ta) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas->pandas_ta) (1.16.0)\n",
            "Building wheels for collected packages: pandas_ta\n",
            "  Building wheel for pandas_ta (setup.py): started\n",
            "  Building wheel for pandas_ta (setup.py): finished with status 'done'\n",
            "  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218924 sha256=b460c03e93cf34447c0b2d272ab89c43be0516f3a6c35ebc7cb571c92c604a2b\n",
            "  Stored in directory: c:\\users\\davide\\appdata\\local\\pip\\cache\\wheels\\7f\\33\\8b\\50b245c5c65433cd8f5cb24ac15d97e5a3db2d41a8b6ae957d\n",
            "Successfully built pandas_ta\n",
            "Installing collected packages: pandas_ta\n",
            "Successfully installed pandas_ta-0.3.14b0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install yfinance\n",
        "! pip install optuna\n",
        "! pip install pandas_ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K9IRGy4AKCBd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import optuna\n",
        "import pandas as pd\n",
        "from processing.pipeline import financial_data_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awNBjHJEKwaY",
        "outputId": "d8fb6882-536c-4f13-b3af-3e13ca3a6bfc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "data = yf.download(\"^STOXX50E\", period=\"max\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "pr_data = financial_data_pipeline.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>BBL_20_2</th>\n",
              "      <th>BBM_20_2</th>\n",
              "      <th>BBU_20_2</th>\n",
              "      <th>BBB_20_2</th>\n",
              "      <th>BBP_20_2</th>\n",
              "      <th>RSI</th>\n",
              "      <th>Month_sin</th>\n",
              "      <th>Month_cos</th>\n",
              "      <th>Weekday_sin</th>\n",
              "      <th>Weekday_cos</th>\n",
              "      <th>Date_numeric</th>\n",
              "      <th>Close_t1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2007-04-30</td>\n",
              "      <td>4378.250000</td>\n",
              "      <td>4409.419922</td>\n",
              "      <td>4370.270020</td>\n",
              "      <td>4392.339844</td>\n",
              "      <td>0</td>\n",
              "      <td>4186.815013</td>\n",
              "      <td>4329.183008</td>\n",
              "      <td>4471.551002</td>\n",
              "      <td>6.577130</td>\n",
              "      <td>0.721808</td>\n",
              "      <td>64.894802</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13633</td>\n",
              "      <td>4415.479980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2007-05-02</td>\n",
              "      <td>4401.939941</td>\n",
              "      <td>4423.839844</td>\n",
              "      <td>4397.339844</td>\n",
              "      <td>4415.479980</td>\n",
              "      <td>0</td>\n",
              "      <td>4211.219223</td>\n",
              "      <td>4340.905518</td>\n",
              "      <td>4470.591812</td>\n",
              "      <td>5.975080</td>\n",
              "      <td>0.787519</td>\n",
              "      <td>67.763024</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.974928</td>\n",
              "      <td>-0.222521</td>\n",
              "      <td>13635</td>\n",
              "      <td>4427.319824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2007-05-03</td>\n",
              "      <td>4429.500000</td>\n",
              "      <td>4432.169922</td>\n",
              "      <td>4394.189941</td>\n",
              "      <td>4427.319824</td>\n",
              "      <td>0</td>\n",
              "      <td>4238.055336</td>\n",
              "      <td>4352.794019</td>\n",
              "      <td>4467.532701</td>\n",
              "      <td>5.271956</td>\n",
              "      <td>0.824763</td>\n",
              "      <td>69.151811</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>13636</td>\n",
              "      <td>4445.589844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2007-05-04</td>\n",
              "      <td>4429.279785</td>\n",
              "      <td>4449.330078</td>\n",
              "      <td>4413.040039</td>\n",
              "      <td>4445.589844</td>\n",
              "      <td>0</td>\n",
              "      <td>4252.206227</td>\n",
              "      <td>4362.758521</td>\n",
              "      <td>4473.310814</td>\n",
              "      <td>5.068000</td>\n",
              "      <td>0.874625</td>\n",
              "      <td>71.212724</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>-0.433884</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>13637</td>\n",
              "      <td>4441.310059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2007-05-07</td>\n",
              "      <td>4448.060059</td>\n",
              "      <td>4452.819824</td>\n",
              "      <td>4432.879883</td>\n",
              "      <td>4441.310059</td>\n",
              "      <td>0</td>\n",
              "      <td>4266.392890</td>\n",
              "      <td>4371.732520</td>\n",
              "      <td>4477.072150</td>\n",
              "      <td>4.819125</td>\n",
              "      <td>0.830253</td>\n",
              "      <td>70.032412</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13640</td>\n",
              "      <td>4411.319824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date         Open         High          Low        Close  Volume  \\\n",
              "19 2007-04-30  4378.250000  4409.419922  4370.270020  4392.339844       0   \n",
              "20 2007-05-02  4401.939941  4423.839844  4397.339844  4415.479980       0   \n",
              "21 2007-05-03  4429.500000  4432.169922  4394.189941  4427.319824       0   \n",
              "22 2007-05-04  4429.279785  4449.330078  4413.040039  4445.589844       0   \n",
              "23 2007-05-07  4448.060059  4452.819824  4432.879883  4441.310059       0   \n",
              "\n",
              "       BBL_20_2     BBM_20_2     BBU_20_2  BBB_20_2  BBP_20_2        RSI  \\\n",
              "19  4186.815013  4329.183008  4471.551002  6.577130  0.721808  64.894802   \n",
              "20  4211.219223  4340.905518  4470.591812  5.975080  0.787519  67.763024   \n",
              "21  4238.055336  4352.794019  4467.532701  5.271956  0.824763  69.151811   \n",
              "22  4252.206227  4362.758521  4473.310814  5.068000  0.874625  71.212724   \n",
              "23  4266.392890  4371.732520  4477.072150  4.819125  0.830253  70.032412   \n",
              "\n",
              "    Month_sin  Month_cos  Weekday_sin  Weekday_cos  Date_numeric     Close_t1  \n",
              "19   0.866025  -0.500000     0.000000     1.000000         13633  4415.479980  \n",
              "20   0.500000  -0.866025     0.974928    -0.222521         13635  4427.319824  \n",
              "21   0.500000  -0.866025     0.433884    -0.900969         13636  4445.589844  \n",
              "22   0.500000  -0.866025    -0.433884    -0.900969         13637  4441.310059  \n",
              "23   0.500000  -0.866025     0.000000     1.000000         13640  4411.319824  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pr_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH6eNE2oyJMh",
        "outputId": "07199294-4028-4b64-db42-476d1ace611d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(           Date         Open         High          Low        Close    Volume  \\\n",
              " 19   2007-04-30  4378.250000  4409.419922  4370.270020  4392.339844         0   \n",
              " 20   2007-05-02  4401.939941  4423.839844  4397.339844  4415.479980         0   \n",
              " 21   2007-05-03  4429.500000  4432.169922  4394.189941  4427.319824         0   \n",
              " 22   2007-05-04  4429.279785  4449.330078  4413.040039  4445.589844         0   \n",
              " 23   2007-05-07  4448.060059  4452.819824  4432.879883  4441.310059         0   \n",
              " ...         ...          ...          ...          ...          ...       ...   \n",
              " 4290 2024-05-10  5060.729980  5096.890137  5060.729980  5085.080078  33566400   \n",
              " 4291 2024-05-13  5083.540039  5087.919922  5068.060059  5078.959961  23625800   \n",
              " 4292 2024-05-14  5079.370117  5083.549805  5057.939941  5080.290039  35579700   \n",
              " 4293 2024-05-15  5083.250000  5102.299805  5075.060059  5100.899902  28208300   \n",
              " 4294 2024-05-16  5094.770020  5101.410156  5068.109863  5072.450195  26348900   \n",
              " \n",
              "          BBL_20_2     BBM_20_2     BBU_20_2  BBB_20_2  BBP_20_2        RSI  \\\n",
              " 19    4186.815013  4329.183008  4471.551002  6.577130  0.721808  64.894802   \n",
              " 20    4211.219223  4340.905518  4470.591812  5.975080  0.787519  67.763024   \n",
              " 21    4238.055336  4352.794019  4467.532701  5.271956  0.824763  69.151811   \n",
              " 22    4252.206227  4362.758521  4473.310814  5.068000  0.874625  71.212724   \n",
              " 23    4266.392890  4371.732520  4477.072150  4.819125  0.830253  70.032412   \n",
              " ...           ...          ...          ...       ...       ...        ...   \n",
              " 4290  4868.124891  4964.170972  5060.217053  3.869572  1.129433  61.983802   \n",
              " 4291  4861.466794  4969.784961  5078.103128  4.359069  1.003955  61.162932   \n",
              " 4292  4857.835240  4976.048975  5094.262709  4.751309  0.940901  61.282938   \n",
              " 4293  4851.707436  4981.869971  5112.032506  5.225449  0.957236  63.181409   \n",
              " 4294  4857.356586  4989.642969  5121.929351  5.302439  0.812985  58.888796   \n",
              " \n",
              "       Month_sin  Month_cos  Weekday_sin  Weekday_cos  Date_numeric  \n",
              " 19     0.866025  -0.500000     0.000000     1.000000         13633  \n",
              " 20     0.500000  -0.866025     0.974928    -0.222521         13635  \n",
              " 21     0.500000  -0.866025     0.433884    -0.900969         13636  \n",
              " 22     0.500000  -0.866025    -0.433884    -0.900969         13637  \n",
              " 23     0.500000  -0.866025     0.000000     1.000000         13640  \n",
              " ...         ...        ...          ...          ...           ...  \n",
              " 4290   0.500000  -0.866025    -0.433884    -0.900969         19853  \n",
              " 4291   0.500000  -0.866025     0.000000     1.000000         19856  \n",
              " 4292   0.500000  -0.866025     0.781831     0.623490         19857  \n",
              " 4293   0.500000  -0.866025     0.974928    -0.222521         19858  \n",
              " 4294   0.500000  -0.866025     0.433884    -0.900969         19859  \n",
              " \n",
              " [4276 rows x 17 columns],\n",
              " array([[[4411.31982422]],\n",
              " \n",
              "        [[4391.87011719]],\n",
              " \n",
              "        [[4423.06982422]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[5100.89990234]],\n",
              " \n",
              "        [[5072.45019531]],\n",
              " \n",
              "        [[5064.14013672]]]))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = pr_data.drop('Close_t1', axis=1)\n",
        "y = pr_data['Close_t1']\n",
        "y = y[4:].reset_index(drop=True).values.reshape(-1, 1, 1)\n",
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg05p4SiydAQ",
        "outputId": "b4a3e1bb-025c-4015-b33c-c9ccc28ba19c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 1.17806400e+18,  4.40193994e+03,  4.42383984e+03,\n",
              "          4.39733984e+03,  4.41547998e+03,  0.00000000e+00,\n",
              "          4.21121922e+03,  4.34090552e+03,  4.47059181e+03,\n",
              "          5.97508026e+00,  7.87518674e-01,  6.77630239e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  9.74927912e-01,\n",
              "         -2.22520934e-01,  1.36350000e+04],\n",
              "        [ 1.17815040e+18,  4.42950000e+03,  4.43216992e+03,\n",
              "          4.39418994e+03,  4.42731982e+03,  0.00000000e+00,\n",
              "          4.23805534e+03,  4.35279402e+03,  4.46753270e+03,\n",
              "          5.27195553e+00,  8.24763210e-01,  6.91518110e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  4.33883739e-01,\n",
              "         -9.00968868e-01,  1.36360000e+04],\n",
              "        [ 1.17823680e+18,  4.42927979e+03,  4.44933008e+03,\n",
              "          4.41304004e+03,  4.44558984e+03,  0.00000000e+00,\n",
              "          4.25220623e+03,  4.36275852e+03,  4.47331081e+03,\n",
              "          5.06799965e+00,  8.74625079e-01,  7.12127240e+01,\n",
              "          5.00000000e-01, -8.66025404e-01, -4.33883739e-01,\n",
              "         -9.00968868e-01,  1.36370000e+04],\n",
              "        [ 1.17849600e+18,  4.44806006e+03,  4.45281982e+03,\n",
              "          4.43287988e+03,  4.44131006e+03,  0.00000000e+00,\n",
              "          4.26639289e+03,  4.37173252e+03,  4.47707215e+03,\n",
              "          4.81912512e+00,  8.30253386e-01,  7.00324123e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  0.00000000e+00,\n",
              "          1.00000000e+00,  1.36400000e+04],\n",
              "        [ 1.17858240e+18,  4.43495996e+03,  4.43560010e+03,\n",
              "          4.39800977e+03,  4.41131982e+03,  0.00000000e+00,\n",
              "          4.28276955e+03,  4.37872151e+03,  4.47467347e+03,\n",
              "          4.38264717e+00,  6.69867903e-01,  6.22467052e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  7.81831482e-01,\n",
              "          6.23489802e-01,  1.36410000e+04]]),\n",
              " array([[ 1.71529920e+18,  5.06072998e+03,  5.09689014e+03,\n",
              "          5.06072998e+03,  5.08508008e+03,  3.35664000e+07,\n",
              "          4.86812489e+03,  4.96417097e+03,  5.06021705e+03,\n",
              "          3.86957184e+00,  1.12943279e+00,  6.19838024e+01,\n",
              "          5.00000000e-01, -8.66025404e-01, -4.33883739e-01,\n",
              "         -9.00968868e-01,  1.98530000e+04],\n",
              "        [ 1.71555840e+18,  5.08354004e+03,  5.08791992e+03,\n",
              "          5.06806006e+03,  5.07895996e+03,  2.36258000e+07,\n",
              "          4.86146679e+03,  4.96978496e+03,  5.07810313e+03,\n",
              "          4.35906858e+00,  1.00395517e+00,  6.11629321e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  0.00000000e+00,\n",
              "          1.00000000e+00,  1.98560000e+04],\n",
              "        [ 1.71564480e+18,  5.07937012e+03,  5.08354980e+03,\n",
              "          5.05793994e+03,  5.08029004e+03,  3.55797000e+07,\n",
              "          4.85783524e+03,  4.97604897e+03,  5.09426271e+03,\n",
              "          4.75130914e+00,  9.40900817e-01,  6.12829375e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  7.81831482e-01,\n",
              "          6.23489802e-01,  1.98570000e+04],\n",
              "        [ 1.71573120e+18,  5.08325000e+03,  5.10229980e+03,\n",
              "          5.07506006e+03,  5.10089990e+03,  2.82083000e+07,\n",
              "          4.85170744e+03,  4.98186997e+03,  5.11203251e+03,\n",
              "          5.22544892e+00,  9.57235761e-01,  6.31814094e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  9.74927912e-01,\n",
              "         -2.22520934e-01,  1.98580000e+04],\n",
              "        [ 1.71581760e+18,  5.09477002e+03,  5.10141016e+03,\n",
              "          5.06810986e+03,  5.07245020e+03,  2.63489000e+07,\n",
              "          4.85735659e+03,  4.98964297e+03,  5.12192935e+03,\n",
              "          5.30243880e+00,  8.12984697e-01,  5.88887956e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  4.33883739e-01,\n",
              "         -9.00968868e-01,  1.98590000e+04]]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "window_size = 5\n",
        "\n",
        "# Initialize an empty list to store 3D arrays\n",
        "X_3d_list = []\n",
        "\n",
        "# Iterate through each window\n",
        "for i in range(len(X) - window_size + 1):\n",
        "    # Extract the data for the current window\n",
        "    window_data = X.iloc[i:i+window_size]\n",
        "    # Convert the window data to a 2D numpy array\n",
        "    window_array = window_data.drop(columns=['Date']).to_numpy()\n",
        "    # Append the 2D array with the date column included as the first feature\n",
        "    window_array_with_time = np.insert(window_array, 0, window_data['Date'], axis=1)\n",
        "    # Append the 2D array to the list\n",
        "    X_3d_list.append(window_array_with_time)\n",
        "\n",
        "# Stack the list of 3D arrays into a single 3D numpy array\n",
        "X_3d = np.stack(X_3d_list)\n",
        "\n",
        "\n",
        "X_3d[1], X_3d[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nbciFEZ0lNM8"
      },
      "outputs": [],
      "source": [
        "X_train, X_remainder, y_train, y_remainder = train_test_split(X_3d, y, test_size=0.3, shuffle=False)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_remainder, y_remainder, test_size=0.333, shuffle=False)\n",
        "X_test, X_forecast, y_test, y_forecast = train_test_split(X_test, y_test, test_size=0.2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU_8w_XAmZlq",
        "outputId": "3b678615-9e2a-4f87-c217-7e16c746d1ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2990, 855, 341, 86, 855)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train), len(X_val), len(X_test), len(X_forecast), len(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vIkDbiZSn7ZI"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XtujuP2aryjg"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YBPBG6AYrxw_"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "validation_dataset = CustomDataset(X_val, y_val)\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "forecast_dataset = CustomDataset(X_forecast, y_forecast)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "forecast_dataloader = DataLoader(forecast_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.17789120e+18,  4.37825000e+03,  4.40941992e+03,\n",
              "         4.37027002e+03,  4.39233984e+03,  0.00000000e+00,\n",
              "         4.18681501e+03,  4.32918301e+03,  4.47155100e+03,\n",
              "         6.57712988e+00,  7.21808406e-01,  6.48948025e+01,\n",
              "         8.66025404e-01, -5.00000000e-01,  0.00000000e+00,\n",
              "         1.00000000e+00,  1.36330000e+04],\n",
              "       [ 1.17806400e+18,  4.40193994e+03,  4.42383984e+03,\n",
              "         4.39733984e+03,  4.41547998e+03,  0.00000000e+00,\n",
              "         4.21121922e+03,  4.34090552e+03,  4.47059181e+03,\n",
              "         5.97508026e+00,  7.87518674e-01,  6.77630239e+01,\n",
              "         5.00000000e-01, -8.66025404e-01,  9.74927912e-01,\n",
              "        -2.22520934e-01,  1.36350000e+04],\n",
              "       [ 1.17815040e+18,  4.42950000e+03,  4.43216992e+03,\n",
              "         4.39418994e+03,  4.42731982e+03,  0.00000000e+00,\n",
              "         4.23805534e+03,  4.35279402e+03,  4.46753270e+03,\n",
              "         5.27195553e+00,  8.24763210e-01,  6.91518110e+01,\n",
              "         5.00000000e-01, -8.66025404e-01,  4.33883739e-01,\n",
              "        -9.00968868e-01,  1.36360000e+04],\n",
              "       [ 1.17823680e+18,  4.42927979e+03,  4.44933008e+03,\n",
              "         4.41304004e+03,  4.44558984e+03,  0.00000000e+00,\n",
              "         4.25220623e+03,  4.36275852e+03,  4.47331081e+03,\n",
              "         5.06799965e+00,  8.74625079e-01,  7.12127240e+01,\n",
              "         5.00000000e-01, -8.66025404e-01, -4.33883739e-01,\n",
              "        -9.00968868e-01,  1.36370000e+04],\n",
              "       [ 1.17849600e+18,  4.44806006e+03,  4.45281982e+03,\n",
              "         4.43287988e+03,  4.44131006e+03,  0.00000000e+00,\n",
              "         4.26639289e+03,  4.37173252e+03,  4.47707215e+03,\n",
              "         4.81912512e+00,  8.30253386e-01,  7.00324123e+01,\n",
              "         5.00000000e-01, -8.66025404e-01,  0.00000000e+00,\n",
              "         1.00000000e+00,  1.36400000e+04]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zjZLKLqk7EvS"
      },
      "outputs": [],
      "source": [
        "for batch in train_dataloader:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hVseQgSRg8AU"
      },
      "outputs": [],
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout_prob):\n",
        "        super(GRUModel, self).__init__()\n",
        "\n",
        "        self.layer_dim = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, _ = self.gru(x, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5GS6YDuPwCQt"
      },
      "outputs": [],
      "source": [
        "input_dim = X_train.shape[2]\n",
        "output_dim = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jMZ795NY3Aao"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "num_trials = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrGs6cpnVK2V",
        "outputId": "3cb36432-8e0f-4060-e675-e0fefc7c9a36"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 12:07:46,036] A new study created in memory with name: no-name-dd5d2abc-0348-40a2-ba37-339256fe3b8c\n",
            "C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([14, 1, 1])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([23, 1, 1])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[I 2024-05-19 12:09:39,313] Trial 0 finished with value: 12645913.851851853 and parameters: {'learning_rate': 0.00026711118232384217, 'hidden_dim': 419, 'num_layers': 3, 'dropout': 0.23239200605387894}. Best is trial 0 with value: 12645913.851851853.\n"
          ]
        }
      ],
      "source": [
        "# Define the objective function for hyperparameter optimization\n",
        "def objective(trial):\n",
        "    # Sample hyperparameters\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
        "    hidden_dim = trial.suggest_int('hidden_dim', 32, 512, log=True)\n",
        "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
        "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
        "\n",
        "    # Define and initialize the model\n",
        "    model = GRUModel(input_dim, hidden_dim, num_layers, output_dim, dropout)\n",
        "\n",
        "    # Define optimizer and criterion\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for inputs, targets in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs = inputs.float()\n",
        "            targets = targets.float()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        validation_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in validation_dataloader:\n",
        "                inputs = inputs.float()\n",
        "                targets = targets.float()\n",
        "                outputs = model(inputs)\n",
        "                validation_loss += criterion(outputs, targets).item()\n",
        "\n",
        "        validation_loss /= len(validation_dataloader)\n",
        "\n",
        "        # Report intermediate results to Optuna\n",
        "        trial.report(validation_loss, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate results\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return validation_loss\n",
        "\n",
        "# Create a study object with TPE sampler\n",
        "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective, n_trials=num_trials)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYGvTVLUZeTU",
        "outputId": "70f69404-bfbf-469c-f7b6-1dcffee69aad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'learning_rate': 0.0037751854616517506,\n",
              " 'hidden_dim': 291,\n",
              " 'num_layers': 2,\n",
              " 'dropout': 0.08608821446980097}"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "AJ0Re7nLaTyj"
      },
      "outputs": [],
      "source": [
        "best_lr = best_params['learning_rate']\n",
        "best_hd = best_params['hidden_dim']\n",
        "best_nl = best_params['num_layers']\n",
        "best_do = best_params['dropout']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "bwpe0Bg6cFIN"
      },
      "outputs": [],
      "source": [
        "X_tv = np.concatenate((X_train, X_val), axis=0)\n",
        "y_tv = np.concatenate((y_train, y_val), axis=0)\n",
        "\n",
        "tv_dataset = CustomDataset(X_tv, y_tv)\n",
        "tv_dataloader = DataLoader(tv_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "X-eq897VcFFJ"
      },
      "outputs": [],
      "source": [
        "cv_model = GRUModel(input_dim, best_hd, best_nl, output_dim, best_do)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "PoPI90jQewif"
      },
      "outputs": [],
      "source": [
        "cv_num_epochs = 10\n",
        "cv_criterion = nn.MSELoss()\n",
        "cv_optimizer = torch.optim.Adam(cv_model.parameters(), lr=best_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdA2qbEOeOEa",
        "outputId": "219844c9-6551-4ed1-a3fd-f84b4e7e07c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([23, 1, 1])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(cv_num_epochs):\n",
        "    cv_model.train()\n",
        "    for inputs, targets in tv_dataloader:\n",
        "        cv_optimizer.zero_grad()\n",
        "        inputs = inputs.float()\n",
        "        targets = targets.float()\n",
        "        outputs = cv_model(inputs)\n",
        "        loss = cv_criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        cv_optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubWWxlEieN7u",
        "outputId": "2b748c47-10d0-4f13-8f5d-89237a58048f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 8714271.818181818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([23, 1, 1])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "cv_model.eval()\n",
        "with torch.no_grad():\n",
        "    test_loss = 0\n",
        "    for inputs, targets in test_dataloader:\n",
        "        inputs = inputs.float()\n",
        "        targets = targets.float()\n",
        "        outputs = cv_model(inputs)\n",
        "        test_loss += cv_criterion(outputs, targets).item()\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "print(f'Test Loss: {test_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XLFeKlTeN4W",
        "outputId": "0b3a6ade-b9e9-4dc7-fcb7-ec3d663255ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forecast Loss: 13555126.666666666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([22, 1, 1])) that is different to the input size (torch.Size([22, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "cv_model.eval()\n",
        "with torch.no_grad():\n",
        "    forecast_loss = 0\n",
        "    for inputs, targets in forecast_dataloader:\n",
        "        inputs = inputs.float()\n",
        "        targets = targets.float()\n",
        "        outputs = cv_model(inputs)\n",
        "        forecast_loss += cv_criterion(outputs, targets).item()\n",
        "\n",
        "    forecast_loss /= len(forecast_dataloader)\n",
        "\n",
        "print(f'Forecast Loss: {forecast_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD95o5z2eN1j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L098VtNkeNyy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuJfwpR7cE-5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOyri4FA26fK"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

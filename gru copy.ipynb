{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR63sM6_IkYN",
        "outputId": "d7693de4-9dfb-4267-a451-ab331f75cbb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: yfinance in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (0.2.38)\n",
            "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.31 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (3.17.5)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
            "Requirement already satisfied: six>=1.9 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.31->yfinance) (3.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.31->yfinance) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.31->yfinance) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.31->yfinance) (2022.12.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: optuna in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (3.6.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (2.0.4)\n",
            "Requirement already satisfied: tqdm in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: Mako in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from alembic>=1.5.0->optuna) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=4 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from colorlog->optuna) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pandas_ta\n",
            "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
            "     ---------------------------------------- 0.0/115.1 kB ? eta -:--:--\n",
            "     -------------------------------------- 115.1/115.1 kB 7.0 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: pandas in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from pandas_ta) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from pandas->pandas_ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from pandas->pandas_ta) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from pandas->pandas_ta) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\davide\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas->pandas_ta) (1.16.0)\n",
            "Building wheels for collected packages: pandas_ta\n",
            "  Building wheel for pandas_ta (setup.py): started\n",
            "  Building wheel for pandas_ta (setup.py): finished with status 'done'\n",
            "  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218924 sha256=b460c03e93cf34447c0b2d272ab89c43be0516f3a6c35ebc7cb571c92c604a2b\n",
            "  Stored in directory: c:\\users\\davide\\appdata\\local\\pip\\cache\\wheels\\7f\\33\\8b\\50b245c5c65433cd8f5cb24ac15d97e5a3db2d41a8b6ae957d\n",
            "Successfully built pandas_ta\n",
            "Installing collected packages: pandas_ta\n",
            "Successfully installed pandas_ta-0.3.14b0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install yfinance\n",
        "! pip install optuna\n",
        "! pip install pandas_ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K9IRGy4AKCBd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import optuna\n",
        "import pandas as pd\n",
        "from processing.pipeline import financial_data_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awNBjHJEKwaY",
        "outputId": "d8fb6882-536c-4f13-b3af-3e13ca3a6bfc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "data = yf.download(\"^STOXX50E\", period=\"max\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "pr_data = financial_data_pipeline.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>BBL_20_2</th>\n",
              "      <th>BBM_20_2</th>\n",
              "      <th>BBU_20_2</th>\n",
              "      <th>BBB_20_2</th>\n",
              "      <th>BBP_20_2</th>\n",
              "      <th>RSI</th>\n",
              "      <th>Month_sin</th>\n",
              "      <th>Month_cos</th>\n",
              "      <th>Weekday_sin</th>\n",
              "      <th>Weekday_cos</th>\n",
              "      <th>Date_numeric</th>\n",
              "      <th>Close_t1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2007-04-30</td>\n",
              "      <td>4378.250000</td>\n",
              "      <td>4409.419922</td>\n",
              "      <td>4370.270020</td>\n",
              "      <td>4392.339844</td>\n",
              "      <td>0</td>\n",
              "      <td>4186.815013</td>\n",
              "      <td>4329.183008</td>\n",
              "      <td>4471.551002</td>\n",
              "      <td>6.577130</td>\n",
              "      <td>0.721808</td>\n",
              "      <td>64.894802</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13633</td>\n",
              "      <td>4415.479980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2007-05-02</td>\n",
              "      <td>4401.939941</td>\n",
              "      <td>4423.839844</td>\n",
              "      <td>4397.339844</td>\n",
              "      <td>4415.479980</td>\n",
              "      <td>0</td>\n",
              "      <td>4211.219223</td>\n",
              "      <td>4340.905518</td>\n",
              "      <td>4470.591812</td>\n",
              "      <td>5.975080</td>\n",
              "      <td>0.787519</td>\n",
              "      <td>67.763024</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.974928</td>\n",
              "      <td>-0.222521</td>\n",
              "      <td>13635</td>\n",
              "      <td>4427.319824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2007-05-03</td>\n",
              "      <td>4429.500000</td>\n",
              "      <td>4432.169922</td>\n",
              "      <td>4394.189941</td>\n",
              "      <td>4427.319824</td>\n",
              "      <td>0</td>\n",
              "      <td>4238.055336</td>\n",
              "      <td>4352.794019</td>\n",
              "      <td>4467.532701</td>\n",
              "      <td>5.271956</td>\n",
              "      <td>0.824763</td>\n",
              "      <td>69.151811</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.433884</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>13636</td>\n",
              "      <td>4445.589844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2007-05-04</td>\n",
              "      <td>4429.279785</td>\n",
              "      <td>4449.330078</td>\n",
              "      <td>4413.040039</td>\n",
              "      <td>4445.589844</td>\n",
              "      <td>0</td>\n",
              "      <td>4252.206227</td>\n",
              "      <td>4362.758521</td>\n",
              "      <td>4473.310814</td>\n",
              "      <td>5.068000</td>\n",
              "      <td>0.874625</td>\n",
              "      <td>71.212724</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>-0.433884</td>\n",
              "      <td>-0.900969</td>\n",
              "      <td>13637</td>\n",
              "      <td>4441.310059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2007-05-07</td>\n",
              "      <td>4448.060059</td>\n",
              "      <td>4452.819824</td>\n",
              "      <td>4432.879883</td>\n",
              "      <td>4441.310059</td>\n",
              "      <td>0</td>\n",
              "      <td>4266.392890</td>\n",
              "      <td>4371.732520</td>\n",
              "      <td>4477.072150</td>\n",
              "      <td>4.819125</td>\n",
              "      <td>0.830253</td>\n",
              "      <td>70.032412</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13640</td>\n",
              "      <td>4411.319824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date         Open         High          Low        Close  Volume  \\\n",
              "19 2007-04-30  4378.250000  4409.419922  4370.270020  4392.339844       0   \n",
              "20 2007-05-02  4401.939941  4423.839844  4397.339844  4415.479980       0   \n",
              "21 2007-05-03  4429.500000  4432.169922  4394.189941  4427.319824       0   \n",
              "22 2007-05-04  4429.279785  4449.330078  4413.040039  4445.589844       0   \n",
              "23 2007-05-07  4448.060059  4452.819824  4432.879883  4441.310059       0   \n",
              "\n",
              "       BBL_20_2     BBM_20_2     BBU_20_2  BBB_20_2  BBP_20_2        RSI  \\\n",
              "19  4186.815013  4329.183008  4471.551002  6.577130  0.721808  64.894802   \n",
              "20  4211.219223  4340.905518  4470.591812  5.975080  0.787519  67.763024   \n",
              "21  4238.055336  4352.794019  4467.532701  5.271956  0.824763  69.151811   \n",
              "22  4252.206227  4362.758521  4473.310814  5.068000  0.874625  71.212724   \n",
              "23  4266.392890  4371.732520  4477.072150  4.819125  0.830253  70.032412   \n",
              "\n",
              "    Month_sin  Month_cos  Weekday_sin  Weekday_cos  Date_numeric     Close_t1  \n",
              "19   0.866025  -0.500000     0.000000     1.000000         13633  4415.479980  \n",
              "20   0.500000  -0.866025     0.974928    -0.222521         13635  4427.319824  \n",
              "21   0.500000  -0.866025     0.433884    -0.900969         13636  4445.589844  \n",
              "22   0.500000  -0.866025    -0.433884    -0.900969         13637  4441.310059  \n",
              "23   0.500000  -0.866025     0.000000     1.000000         13640  4411.319824  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pr_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH6eNE2oyJMh",
        "outputId": "07199294-4028-4b64-db42-476d1ace611d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(           Date         Open         High          Low        Close    Volume  \\\n",
              " 19   2007-04-30  4378.250000  4409.419922  4370.270020  4392.339844         0   \n",
              " 20   2007-05-02  4401.939941  4423.839844  4397.339844  4415.479980         0   \n",
              " 21   2007-05-03  4429.500000  4432.169922  4394.189941  4427.319824         0   \n",
              " 22   2007-05-04  4429.279785  4449.330078  4413.040039  4445.589844         0   \n",
              " 23   2007-05-07  4448.060059  4452.819824  4432.879883  4441.310059         0   \n",
              " ...         ...          ...          ...          ...          ...       ...   \n",
              " 4290 2024-05-10  5060.729980  5096.890137  5060.729980  5085.080078  33566400   \n",
              " 4291 2024-05-13  5083.540039  5087.919922  5068.060059  5078.959961  23625800   \n",
              " 4292 2024-05-14  5079.370117  5083.549805  5057.939941  5080.290039  35579700   \n",
              " 4293 2024-05-15  5083.250000  5102.299805  5075.060059  5100.899902  28208300   \n",
              " 4294 2024-05-16  5094.770020  5101.410156  5068.109863  5072.450195  26348900   \n",
              " \n",
              "          BBL_20_2     BBM_20_2     BBU_20_2  BBB_20_2  BBP_20_2        RSI  \\\n",
              " 19    4186.815013  4329.183008  4471.551002  6.577130  0.721808  64.894802   \n",
              " 20    4211.219223  4340.905518  4470.591812  5.975080  0.787519  67.763024   \n",
              " 21    4238.055336  4352.794019  4467.532701  5.271956  0.824763  69.151811   \n",
              " 22    4252.206227  4362.758521  4473.310814  5.068000  0.874625  71.212724   \n",
              " 23    4266.392890  4371.732520  4477.072150  4.819125  0.830253  70.032412   \n",
              " ...           ...          ...          ...       ...       ...        ...   \n",
              " 4290  4868.124891  4964.170972  5060.217053  3.869572  1.129433  61.983802   \n",
              " 4291  4861.466794  4969.784961  5078.103128  4.359069  1.003955  61.162932   \n",
              " 4292  4857.835240  4976.048975  5094.262709  4.751309  0.940901  61.282938   \n",
              " 4293  4851.707436  4981.869971  5112.032506  5.225449  0.957236  63.181409   \n",
              " 4294  4857.356586  4989.642969  5121.929351  5.302439  0.812985  58.888796   \n",
              " \n",
              "       Month_sin  Month_cos  Weekday_sin  Weekday_cos  Date_numeric  \n",
              " 19     0.866025  -0.500000     0.000000     1.000000         13633  \n",
              " 20     0.500000  -0.866025     0.974928    -0.222521         13635  \n",
              " 21     0.500000  -0.866025     0.433884    -0.900969         13636  \n",
              " 22     0.500000  -0.866025    -0.433884    -0.900969         13637  \n",
              " 23     0.500000  -0.866025     0.000000     1.000000         13640  \n",
              " ...         ...        ...          ...          ...           ...  \n",
              " 4290   0.500000  -0.866025    -0.433884    -0.900969         19853  \n",
              " 4291   0.500000  -0.866025     0.000000     1.000000         19856  \n",
              " 4292   0.500000  -0.866025     0.781831     0.623490         19857  \n",
              " 4293   0.500000  -0.866025     0.974928    -0.222521         19858  \n",
              " 4294   0.500000  -0.866025     0.433884    -0.900969         19859  \n",
              " \n",
              " [4276 rows x 17 columns],\n",
              " array([[[4411.31982422]],\n",
              " \n",
              "        [[4391.87011719]],\n",
              " \n",
              "        [[4423.06982422]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[5100.89990234]],\n",
              " \n",
              "        [[5072.45019531]],\n",
              " \n",
              "        [[5064.14013672]]]))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = pr_data.drop('Close_t1', axis=1)\n",
        "y = pr_data['Close_t1']\n",
        "y = y[4:].reset_index(drop=True).values.reshape(-1, 1, 1)\n",
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg05p4SiydAQ",
        "outputId": "b4a3e1bb-025c-4015-b33c-c9ccc28ba19c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 1.17806400e+18,  4.40193994e+03,  4.42383984e+03,\n",
              "          4.39733984e+03,  4.41547998e+03,  0.00000000e+00,\n",
              "          4.21121922e+03,  4.34090552e+03,  4.47059181e+03,\n",
              "          5.97508026e+00,  7.87518674e-01,  6.77630239e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  9.74927912e-01,\n",
              "         -2.22520934e-01,  1.36350000e+04],\n",
              "        [ 1.17815040e+18,  4.42950000e+03,  4.43216992e+03,\n",
              "          4.39418994e+03,  4.42731982e+03,  0.00000000e+00,\n",
              "          4.23805534e+03,  4.35279402e+03,  4.46753270e+03,\n",
              "          5.27195553e+00,  8.24763210e-01,  6.91518110e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  4.33883739e-01,\n",
              "         -9.00968868e-01,  1.36360000e+04],\n",
              "        [ 1.17823680e+18,  4.42927979e+03,  4.44933008e+03,\n",
              "          4.41304004e+03,  4.44558984e+03,  0.00000000e+00,\n",
              "          4.25220623e+03,  4.36275852e+03,  4.47331081e+03,\n",
              "          5.06799965e+00,  8.74625079e-01,  7.12127240e+01,\n",
              "          5.00000000e-01, -8.66025404e-01, -4.33883739e-01,\n",
              "         -9.00968868e-01,  1.36370000e+04],\n",
              "        [ 1.17849600e+18,  4.44806006e+03,  4.45281982e+03,\n",
              "          4.43287988e+03,  4.44131006e+03,  0.00000000e+00,\n",
              "          4.26639289e+03,  4.37173252e+03,  4.47707215e+03,\n",
              "          4.81912512e+00,  8.30253386e-01,  7.00324123e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  0.00000000e+00,\n",
              "          1.00000000e+00,  1.36400000e+04],\n",
              "        [ 1.17858240e+18,  4.43495996e+03,  4.43560010e+03,\n",
              "          4.39800977e+03,  4.41131982e+03,  0.00000000e+00,\n",
              "          4.28276955e+03,  4.37872151e+03,  4.47467347e+03,\n",
              "          4.38264717e+00,  6.69867903e-01,  6.22467052e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  7.81831482e-01,\n",
              "          6.23489802e-01,  1.36410000e+04]]),\n",
              " array([[ 1.71529920e+18,  5.06072998e+03,  5.09689014e+03,\n",
              "          5.06072998e+03,  5.08508008e+03,  3.35664000e+07,\n",
              "          4.86812489e+03,  4.96417097e+03,  5.06021705e+03,\n",
              "          3.86957184e+00,  1.12943279e+00,  6.19838024e+01,\n",
              "          5.00000000e-01, -8.66025404e-01, -4.33883739e-01,\n",
              "         -9.00968868e-01,  1.98530000e+04],\n",
              "        [ 1.71555840e+18,  5.08354004e+03,  5.08791992e+03,\n",
              "          5.06806006e+03,  5.07895996e+03,  2.36258000e+07,\n",
              "          4.86146679e+03,  4.96978496e+03,  5.07810313e+03,\n",
              "          4.35906858e+00,  1.00395517e+00,  6.11629321e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  0.00000000e+00,\n",
              "          1.00000000e+00,  1.98560000e+04],\n",
              "        [ 1.71564480e+18,  5.07937012e+03,  5.08354980e+03,\n",
              "          5.05793994e+03,  5.08029004e+03,  3.55797000e+07,\n",
              "          4.85783524e+03,  4.97604897e+03,  5.09426271e+03,\n",
              "          4.75130914e+00,  9.40900817e-01,  6.12829375e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  7.81831482e-01,\n",
              "          6.23489802e-01,  1.98570000e+04],\n",
              "        [ 1.71573120e+18,  5.08325000e+03,  5.10229980e+03,\n",
              "          5.07506006e+03,  5.10089990e+03,  2.82083000e+07,\n",
              "          4.85170744e+03,  4.98186997e+03,  5.11203251e+03,\n",
              "          5.22544892e+00,  9.57235761e-01,  6.31814094e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  9.74927912e-01,\n",
              "         -2.22520934e-01,  1.98580000e+04],\n",
              "        [ 1.71581760e+18,  5.09477002e+03,  5.10141016e+03,\n",
              "          5.06810986e+03,  5.07245020e+03,  2.63489000e+07,\n",
              "          4.85735659e+03,  4.98964297e+03,  5.12192935e+03,\n",
              "          5.30243880e+00,  8.12984697e-01,  5.88887956e+01,\n",
              "          5.00000000e-01, -8.66025404e-01,  4.33883739e-01,\n",
              "         -9.00968868e-01,  1.98590000e+04]]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "window_size = 5\n",
        "\n",
        "# Initialize an empty list to store 3D arrays\n",
        "X_3d_list = []\n",
        "\n",
        "# Iterate through each window\n",
        "for i in range(len(X) - window_size + 1):\n",
        "    # Extract the data for the current window\n",
        "    window_data = X.iloc[i:i+window_size]\n",
        "    # Convert the window data to a 2D numpy array\n",
        "    window_array = window_data.drop(columns=['Date']).to_numpy()\n",
        "    # Append the 2D array with the date column included as the first feature\n",
        "    window_array_with_time = np.insert(window_array, 0, window_data['Date'], axis=1)\n",
        "    # Append the 2D array to the list\n",
        "    X_3d_list.append(window_array_with_time)\n",
        "\n",
        "# Stack the list of 3D arrays into a single 3D numpy array\n",
        "X_3d = np.stack(X_3d_list)\n",
        "\n",
        "\n",
        "X_3d[1], X_3d[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nbciFEZ0lNM8"
      },
      "outputs": [],
      "source": [
        "X_train, X_remainder, y_train, y_remainder = train_test_split(X_3d, y, test_size=0.3, shuffle=False)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_remainder, y_remainder, test_size=0.333, shuffle=False)\n",
        "X_test, X_forecast, y_test, y_forecast = train_test_split(X_test, y_test, test_size=0.2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU_8w_XAmZlq",
        "outputId": "3b678615-9e2a-4f87-c217-7e16c746d1ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2990, 855, 341, 86, 855)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train), len(X_val), len(X_test), len(X_forecast), len(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vIkDbiZSn7ZI"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XtujuP2aryjg"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YBPBG6AYrxw_"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "validation_dataset = CustomDataset(X_val, y_val)\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "forecast_dataset = CustomDataset(X_forecast, y_forecast)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "forecast_dataloader = DataLoader(forecast_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.17789120e+18,  4.37825000e+03,  4.40941992e+03,\n",
              "         4.37027002e+03,  4.39233984e+03,  0.00000000e+00,\n",
              "         4.18681501e+03,  4.32918301e+03,  4.47155100e+03,\n",
              "         6.57712988e+00,  7.21808406e-01,  6.48948025e+01,\n",
              "         8.66025404e-01, -5.00000000e-01,  0.00000000e+00,\n",
              "         1.00000000e+00,  1.36330000e+04],\n",
              "       [ 1.17806400e+18,  4.40193994e+03,  4.42383984e+03,\n",
              "         4.39733984e+03,  4.41547998e+03,  0.00000000e+00,\n",
              "         4.21121922e+03,  4.34090552e+03,  4.47059181e+03,\n",
              "         5.97508026e+00,  7.87518674e-01,  6.77630239e+01,\n",
              "         5.00000000e-01, -8.66025404e-01,  9.74927912e-01,\n",
              "        -2.22520934e-01,  1.36350000e+04],\n",
              "       [ 1.17815040e+18,  4.42950000e+03,  4.43216992e+03,\n",
              "         4.39418994e+03,  4.42731982e+03,  0.00000000e+00,\n",
              "         4.23805534e+03,  4.35279402e+03,  4.46753270e+03,\n",
              "         5.27195553e+00,  8.24763210e-01,  6.91518110e+01,\n",
              "         5.00000000e-01, -8.66025404e-01,  4.33883739e-01,\n",
              "        -9.00968868e-01,  1.36360000e+04],\n",
              "       [ 1.17823680e+18,  4.42927979e+03,  4.44933008e+03,\n",
              "         4.41304004e+03,  4.44558984e+03,  0.00000000e+00,\n",
              "         4.25220623e+03,  4.36275852e+03,  4.47331081e+03,\n",
              "         5.06799965e+00,  8.74625079e-01,  7.12127240e+01,\n",
              "         5.00000000e-01, -8.66025404e-01, -4.33883739e-01,\n",
              "        -9.00968868e-01,  1.36370000e+04],\n",
              "       [ 1.17849600e+18,  4.44806006e+03,  4.45281982e+03,\n",
              "         4.43287988e+03,  4.44131006e+03,  0.00000000e+00,\n",
              "         4.26639289e+03,  4.37173252e+03,  4.47707215e+03,\n",
              "         4.81912512e+00,  8.30253386e-01,  7.00324123e+01,\n",
              "         5.00000000e-01, -8.66025404e-01,  0.00000000e+00,\n",
              "         1.00000000e+00,  1.36400000e+04]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zjZLKLqk7EvS"
      },
      "outputs": [],
      "source": [
        "for batch in train_dataloader:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hVseQgSRg8AU"
      },
      "outputs": [],
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout_prob):\n",
        "        super(GRUModel, self).__init__()\n",
        "\n",
        "        self.layer_dim = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, _ = self.gru(x, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5GS6YDuPwCQt"
      },
      "outputs": [],
      "source": [
        "input_dim = X_train.shape[2]\n",
        "output_dim = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jMZ795NY3Aao"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "num_trials = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrGs6cpnVK2V",
        "outputId": "3cb36432-8e0f-4060-e675-e0fefc7c9a36"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-19 12:07:46,036] A new study created in memory with name: no-name-dd5d2abc-0348-40a2-ba37-339256fe3b8c\n",
            "C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([14, 1, 1])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([23, 1, 1])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[I 2024-05-19 12:09:39,313] Trial 0 finished with value: 12645913.851851853 and parameters: {'learning_rate': 0.00026711118232384217, 'hidden_dim': 419, 'num_layers': 3, 'dropout': 0.23239200605387894}. Best is trial 0 with value: 12645913.851851853.\n",
            "[W 2024-05-19 12:10:02,566] Trial 1 failed with parameters: {'learning_rate': 6.0028639412027356e-05, 'hidden_dim': 302, 'num_layers': 3, 'dropout': 0.315994436168046} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Davide\\AppData\\Local\\Temp\\ipykernel_9960\\2816110529.py\", line 23, in objective\n",
            "    outputs = model(inputs)\n",
            "              ^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Davide\\AppData\\Local\\Temp\\ipykernel_9960\\2858060644.py\", line 16, in forward\n",
            "    out, _ = self.gru(x, h0.detach())\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Davide\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py\", line 998, in forward\n",
            "    result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "[W 2024-05-19 12:10:02,568] Trial 1 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[25], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Create a study object with TPE sampler\u001b[39;00m\n\u001b[0;32m     50\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler())\n\u001b[1;32m---> 51\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[0;32m     54\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[25], line 23\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     21\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     22\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m---> 23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "Cell \u001b[1;32mIn[13], line 16\u001b[0m, in \u001b[0;36mGRUModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_dim, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Forward propagation by passing in the input and hidden state into the model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# so that it can fit into the fully connected layer\u001b[39;00m\n\u001b[0;32m     20\u001b[0m out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:998\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 998\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1001\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m   1002\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Define the objective function for hyperparameter optimization\n",
        "def objective(trial):\n",
        "    # Sample hyperparameters\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
        "    hidden_dim = trial.suggest_int('hidden_dim', 32, 512, log=True)\n",
        "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
        "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
        "\n",
        "    # Define and initialize the model\n",
        "    model = GRUModel(input_dim, hidden_dim, num_layers, output_dim, dropout)\n",
        "\n",
        "    # Define optimizer and criterion\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for inputs, targets in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs = inputs.float()\n",
        "            targets = targets.float()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        validation_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in validation_dataloader:\n",
        "                inputs = inputs.float()\n",
        "                targets = targets.float()\n",
        "                outputs = model(inputs)\n",
        "                validation_loss += criterion(outputs, targets).item()\n",
        "\n",
        "        validation_loss /= len(validation_dataloader)\n",
        "\n",
        "        # Report intermediate results to Optuna\n",
        "        trial.report(validation_loss, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate results\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return validation_loss\n",
        "\n",
        "# Create a study object with TPE sampler\n",
        "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective, n_trials=num_trials)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYGvTVLUZeTU",
        "outputId": "70f69404-bfbf-469c-f7b6-1dcffee69aad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'learning_rate': 0.0037751854616517506,\n",
              " 'hidden_dim': 291,\n",
              " 'num_layers': 2,\n",
              " 'dropout': 0.08608821446980097}"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "AJ0Re7nLaTyj"
      },
      "outputs": [],
      "source": [
        "best_lr = best_params['learning_rate']\n",
        "best_hd = best_params['hidden_dim']\n",
        "best_nl = best_params['num_layers']\n",
        "best_do = best_params['dropout']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "bwpe0Bg6cFIN"
      },
      "outputs": [],
      "source": [
        "X_tv = np.concatenate((X_train, X_val), axis=0)\n",
        "y_tv = np.concatenate((y_train, y_val), axis=0)\n",
        "\n",
        "tv_dataset = CustomDataset(X_tv, y_tv)\n",
        "tv_dataloader = DataLoader(tv_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "X-eq897VcFFJ"
      },
      "outputs": [],
      "source": [
        "cv_model = GRUModel(input_dim, best_hd, best_nl, output_dim, best_do)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "PoPI90jQewif"
      },
      "outputs": [],
      "source": [
        "cv_num_epochs = 10\n",
        "cv_criterion = nn.MSELoss()\n",
        "cv_optimizer = torch.optim.Adam(cv_model.parameters(), lr=best_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdA2qbEOeOEa",
        "outputId": "219844c9-6551-4ed1-a3fd-f84b4e7e07c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([23, 1, 1])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(cv_num_epochs):\n",
        "    cv_model.train()\n",
        "    for inputs, targets in tv_dataloader:\n",
        "        cv_optimizer.zero_grad()\n",
        "        inputs = inputs.float()\n",
        "        targets = targets.float()\n",
        "        outputs = cv_model(inputs)\n",
        "        loss = cv_criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        cv_optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubWWxlEieN7u",
        "outputId": "2b748c47-10d0-4f13-8f5d-89237a58048f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 8714271.818181818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([23, 1, 1])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "cv_model.eval()\n",
        "with torch.no_grad():\n",
        "    test_loss = 0\n",
        "    for inputs, targets in test_dataloader:\n",
        "        inputs = inputs.float()\n",
        "        targets = targets.float()\n",
        "        outputs = cv_model(inputs)\n",
        "        test_loss += cv_criterion(outputs, targets).item()\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "print(f'Test Loss: {test_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XLFeKlTeN4W",
        "outputId": "0b3a6ade-b9e9-4dc7-fcb7-ec3d663255ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forecast Loss: 13555126.666666666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([22, 1, 1])) that is different to the input size (torch.Size([22, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "cv_model.eval()\n",
        "with torch.no_grad():\n",
        "    forecast_loss = 0\n",
        "    for inputs, targets in forecast_dataloader:\n",
        "        inputs = inputs.float()\n",
        "        targets = targets.float()\n",
        "        outputs = cv_model(inputs)\n",
        "        forecast_loss += cv_criterion(outputs, targets).item()\n",
        "\n",
        "    forecast_loss /= len(forecast_dataloader)\n",
        "\n",
        "print(f'Forecast Loss: {forecast_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD95o5z2eN1j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L098VtNkeNyy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuJfwpR7cE-5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOyri4FA26fK"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
